// Node.js Runtime ì‚¬ìš© (4MB â†’ 25MB ì—…ë¡œë“œ í•œë„ ì¦ê°€)
export const runtime = "nodejs";

// Route configuration
export const maxDuration = 60;

import { NextRequest, NextResponse } from "next/server";
import { openai, AI_MODEL } from "@/lib/openai";

// Some environments may send OPTIONS (preflight) or GET accidentally.
export async function OPTIONS(request: NextRequest) {
  const origin = request.headers.get("origin") ?? "*";
  console.log("[instructor-chat] OPTIONS /api/instructor/chat (preflight)", {
    origin,
    contentType: request.headers.get("content-type"),
    userAgent: request.headers.get("user-agent")?.slice(0, 80),
  });
  return new NextResponse(null, {
    status: 204,
    headers: {
      "Access-Control-Allow-Origin": origin,
      "Access-Control-Allow-Methods": "POST, OPTIONS",
      "Access-Control-Allow-Headers": "Content-Type, Authorization",
      "Access-Control-Max-Age": "86400",
      Vary: "Origin",
    },
  });
}

export async function GET() {
  console.log("[instructor-chat] GET /api/instructor/chat (healthcheck)");
  return NextResponse.json(
    { ok: true, route: "/api/instructor/chat", methods: ["POST", "OPTIONS"] },
    { status: 200, headers: { Allow: "POST, OPTIONS" } }
  );
}

type InstructorChatRequestBody = {
  message: string;
  sessionId: string;
  context: string;
  scopeDescription?: string;
  userId?: string;
};

// ê³µí†µ Completion í•¨ìˆ˜ - Responses API ì‚¬ìš©
async function getAIResponse(
  systemPrompt: string,
  userMessage: string,
  previousResponseId: string | null = null
): Promise<{ response: string; responseId: string }> {
  const aiStartTime = Date.now();
  try {
    if (process.env.NODE_ENV === "development") {
      console.log(
        "[instructor-chat] Calling OpenAI Responses API with prompt length:",
        systemPrompt.length,
        "| Previous response ID:",
        previousResponseId || "none (first message)"
      );
    }

    // Responses API ì‚¬ìš©
    const response = await openai.responses.create({
      model: AI_MODEL,
      instructions: systemPrompt,
      input: userMessage,
      previous_response_id: previousResponseId || undefined,
      store: true,
    });

    const aiDuration = Date.now() - aiStartTime;
    console.log(
      `â±ï¸  [PERFORMANCE] OpenAI Responses API response time: ${aiDuration}ms`
    );

    if (process.env.NODE_ENV === "development") {
      console.log("[instructor-chat] OpenAI Responses API response received:", {
        responseId: response.id,
        hasOutput: !!response.output,
        outputLength: response.output?.length || 0,
      });
    }

    // output ë°°ì—´ì—ì„œ ë©”ì‹œì§€ íƒ€ì… ì°¾ê¸°
    let responseText = "";
    const outputArray = response.output as any;
    if (outputArray && Array.isArray(outputArray)) {
      const messageOutput = outputArray.find(
        (item: any) => item.type === "message" && item.content
      );

      if (messageOutput && Array.isArray(messageOutput.content)) {
        const textParts = messageOutput.content
          .filter((part: any) => part.type === "output_text" && part.text)
          .map((part: any) => part.text);
        responseText = textParts.join("");
      }
    }

    if (!responseText || responseText.trim().length === 0) {
      console.warn("[instructor-chat] OpenAI returned empty or null response");
      return {
        response:
          "ì£„ì†¡í•©ë‹ˆë‹¤. ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        responseId: response.id,
      };
    }

    return {
      response: responseText,
      responseId: response.id,
    };
  } catch (openaiError) {
    console.error("[instructor-chat] OpenAI Responses API error:", openaiError);
    throw new Error(
      `OpenAI Responses API failed: ${(openaiError as Error).message}`
    );
  }
}

function buildInstructorSystemPrompt(params: {
  context: string;
  scopeDescription?: string;
}): string {
  const { context, scopeDescription = "ì´ í˜ì´ì§€ì˜ ë°ì´í„°" } = params;

  return `
ë‹¹ì‹ ì€ ëŒ€í•™ ê°•ì˜ì˜ êµìˆ˜ì(Professor)ë¡œì„œ ì‹œí—˜ ê´€ë¦¬ ë° ì±„ì ì„ ë³´ì¡°í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì œê³µëœ ì»¨í…ìŠ¤íŠ¸:**
${context}

**ë‹µë³€ ë²”ìœ„:**
- ${scopeDescription} ë²”ìœ„ ì•ˆì—ì„œë§Œ ë‹µë³€í•©ë‹ˆë‹¤.
- ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì»¨í…ìŠ¤íŠ¸ì— ëª…ì‹œëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

**ì—­í• (Role):**
- ì‹œí—˜ ê´€ë¦¬ ë° ì±„ì ì„ ë³´ì¡°í•˜ëŠ” êµìˆ˜ì ì–´ì‹œìŠ¤í„´íŠ¸
- í•™ìƒ ë‹µì•ˆ í‰ê°€, í”¼ë“œë°± ì‘ì„±, ì‹œí—˜ í†µê³„ ë¶„ì„ ë“±ì„ ë„ì™€ì¤ë‹ˆë‹¤
- êµìˆ˜ìì˜ ì˜ì‚¬ê²°ì •ì„ ë•ê¸° ìœ„í•´ ëª…í™•í•˜ê³  êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤

**ê·œì¹™(Rules):**
- í•­ìƒ **ë§ˆí¬ë‹¤ìš´** í˜•ì‹ìœ¼ë¡œ ëŒ€ë‹µí•©ë‹ˆë‹¤.
- ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì¸ í†¤ì„ ìœ ì§€í•©ë‹ˆë‹¤ (~ìŠµë‹ˆë‹¤, ~ì…ë‹ˆë‹¤ ì²´ ì‚¬ìš©).
- í•„ìš”ì‹œ êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ì œì•ˆì„ í¬í•¨í•©ë‹ˆë‹¤.
- ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° ìˆ«ìì™€ í†µê³„ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
- ì±„ì  ê´€ë ¨ ì§ˆë¬¸ì˜ ê²½ìš° í‰ê°€ ê¸°ì¤€ê³¼ í•¨ê»˜ ë‹µë³€í•©ë‹ˆë‹¤.
- ì‹œí—˜ ê´€ë¦¬ ê´€ë ¨ ì§ˆë¬¸ì˜ ê²½ìš° ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.

**ë‹µë³€ ìŠ¤íƒ€ì¼:**
- ê°„ê²°í•˜ë©´ì„œë„ ì¶©ë¶„í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- êµ¬ì¡°í™”ëœ í˜•ì‹(ëª©ë¡, í‘œ ë“±)ì„ ì ì ˆíˆ í™œìš©í•©ë‹ˆë‹¤.
- ì¤‘ìš”í•œ ì •ë³´ëŠ” ê°•ì¡° í‘œì‹œ(**êµµê²Œ**)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
`.trim();
}

export async function POST(request: NextRequest) {
  const requestStartTime = Date.now();
  try {
    console.log("[instructor-chat] incoming request", {
      method: request.method,
      path: request.nextUrl?.pathname,
      contentType: request.headers.get("content-type"),
      origin: request.headers.get("origin"),
      referer: request.headers.get("referer"),
      userAgent: request.headers.get("user-agent")?.slice(0, 80),
    });

    const body = (await request.json()) as InstructorChatRequestBody;

    const { message, sessionId, context, scopeDescription, userId } = body;

    if (!message) {
      return NextResponse.json(
        { error: "Missing message field" },
        { status: 400 }
      );
    }

    if (!context) {
      return NextResponse.json(
        { error: "Missing context field" },
        { status: 400 }
      );
    }

    // ğŸ“Š ì‚¬ìš©ì í™œë™ ë¡œê·¸
    console.log(
      `ğŸ‘¤ [INSTRUCTOR_ACTIVITY] User ${
        userId || "unknown"
      } | Session ${sessionId} | Scope: ${scopeDescription || "N/A"}`
    );

    // êµìˆ˜ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±
    const systemPrompt = buildInstructorSystemPrompt({
      context,
      scopeDescription,
    });

    // ì´ì „ ì‘ë‹µ IDëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (êµìˆ˜ìš©ì€ ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
    const previousResponseId = null;

    const { response: aiResponse } = await getAIResponse(
      systemPrompt,
      message,
      previousResponseId
    );

    const requestDuration = Date.now() - requestStartTime;
    console.log(
      `â±ï¸  [PERFORMANCE] Total request time (instructor-chat): ${requestDuration}ms`
    );

    return NextResponse.json({
      response: aiResponse,
      timestamp: new Date().toISOString(),
    });
  } catch (error) {
    console.error("[instructor-chat] Chat API error:", error);
    const errorMessage = error instanceof Error ? error.message : String(error);
    const errorStack = error instanceof Error ? error.stack : undefined;

    console.error("[instructor-chat] Chat API error details:", {
      message: errorMessage,
      stack: errorStack,
      errorType: typeof error,
    });

    return NextResponse.json(
      {
        error: "Internal server error",
        message:
          "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        details:
          process.env.NODE_ENV === "development" ? errorMessage : undefined,
      },
      { status: 500 }
    );
  }
}
